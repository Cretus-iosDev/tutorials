{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyThaiNLP Get Started\n",
    "\n",
    "Code examples for basic functions in PyThaiNLP https://github.com/PyThaiNLP/pythainlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thai Characters\n",
    "\n",
    "PyThaiNLP provides some ready-to-use Thai character set (e.g. Thai consonants, vowels, tonemarks, symbols) as a string for convenience. There are also few utility functions to test if a string is in Thai or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรลวศษสหฬอฮฤฦะัาำิีึืุูเแโใไๅ็่้๊๋ฯๆฺ์ํ๎๏๚๛๐๑๒๓๔๕๖๗๘๙฿'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pythainlp\n",
    "\n",
    "pythainlp.thai_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรลวศษสหฬอฮ'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pythainlp.thai_consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"๔\" in pythainlp.thai_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pythainlp.util\n",
    "\n",
    "pythainlp.util.isthai(\"ก\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pythainlp.util.isthai(\"(ก.พ.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pythainlp.util.isthai(\"(ก.พ.)\", ignore_chars=\".()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pythainlp.util.countthai(\"วันอาทิตย์ที่ 24 มีนาคม 2562\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.85714285714286"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pythainlp.util.countthai(\"วันอาทิตย์ที่ 24 มีนาคม 2562\", ignore_chars=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collation\n",
    "\n",
    "Sorting according to Thai dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['กรรไกร', 'กระดาษ', 'ไข่', 'ค้อน', 'ผ้าไหม']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pythainlp.util import collate\n",
    "\n",
    "thai_words = [\"ค้อน\", \"กระดาษ\", \"กรรไกร\", \"ไข่\", \"ผ้าไหม\"]\n",
    "collate(thai_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ผ้าไหม', 'ค้อน', 'ไข่', 'กระดาษ', 'กรรไกร']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collate(thai_words, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date and Time Format\n",
    "\n",
    "Get Thai day and month names with Thai Buddhist Era (B.E.).\n",
    "Use formatting directives similar to datetime.strftime()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'วันพุธที่ 6 ตุลาคม พ.ศ. 2519 เวลา 01:40 น. (พ 06-ต.ค.-19)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "from pythainlp.util import thai_strftime\n",
    "\n",
    "fmt = \"%Aที่ %-d %B พ.ศ. %Y เวลา %H:%M น. (%a %d-%b-%y)\"\n",
    "date = datetime.datetime(1976, 10, 6, 1, 40)\n",
    "\n",
    "thai_strftime(date, fmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence and Word\n",
    "\n",
    "Default word tokenizer (\"newmm\") use maximum matching algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent_tokenize: ['ฉันรักภาษาไทย', 'เพราะฉันใช้ภาษาไทย']\n",
      "word_tokenize: ['ฉัน', 'รัก', 'ภาษาไทย', ' ', 'เพราะ', 'ฉัน', 'ใช้', 'ภาษาไทย', ' ']\n",
      "word_tokenize, without whitespace: ['ฉัน', 'รัก', 'ภาษาไทย', 'เพราะ', 'ฉัน', 'ใช้', 'ภาษาไทย']\n"
     ]
    }
   ],
   "source": [
    "from pythainlp import sent_tokenize, word_tokenize\n",
    "\n",
    "text = \"ฉันรักภาษาไทย เพราะฉันใช้ภาษาไทย \"\n",
    "\n",
    "print(\"sent_tokenize:\", sent_tokenize(text))\n",
    "print(\"word_tokenize:\", word_tokenize(text))\n",
    "print(\"word_tokenize, without whitespace:\", word_tokenize(text, keep_whitespace=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other algorithm can be chosen. We can also create a tokenizer with custom dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newmm: ['กฎหมายแรงงาน', 'ฉบับ', 'ปรับปรุง', 'ใหม่', 'ประกาศ', 'ใช้แล้ว']\n",
      "longest: ['กฎหมายแรงงาน', 'ฉบับ', 'ปรับปรุง', 'ใหม่', 'ประกาศใช้', 'แล้ว']\n",
      "custom: ['กฎ', 'หมายแรง', 'งาน', 'ฉบับปรับปรุงใหม่ประกาศใช้แล้ว']\n"
     ]
    }
   ],
   "source": [
    "from pythainlp import word_tokenize, Tokenizer\n",
    "\n",
    "text = \"กฎหมายแรงงานฉบับปรับปรุงใหม่ประกาศใช้แล้ว\"\n",
    "\n",
    "print(\"newmm:\", word_tokenize(text))  # default engine is \"newmm\"\n",
    "print(\"longest:\", word_tokenize(text, engine=\"longest\"))\n",
    "\n",
    "words = [\"กฎ\", \"งาน\"]\n",
    "custom_tokenizer = Tokenizer(words)\n",
    "print(\"custom:\", custom_tokenizer.word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default word tokenizer use a word list from pythainlp.corpus.common.thai_words().\n",
    "We can get that list, add/remove words, and create new tokenizer from the modified list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newmm: ['ไอแซค', ' ', 'อสิ', 'มอ', 'ฟ']\n",
      "custom: ['ไอแซค', ' ', 'อสิมอฟ']\n"
     ]
    }
   ],
   "source": [
    "from pythainlp.corpus.common import thai_words\n",
    "from pythainlp import word_tokenize, Tokenizer\n",
    "\n",
    "text = \"ไอแซค อสิมอฟ\"\n",
    "\n",
    "print(\"newmm:\", word_tokenize(text))\n",
    "\n",
    "words = set(thai_words())  # thai_words() returns frozenset\n",
    "words.add(\"อสิมอฟ\")\n",
    "custom_tokenizer = Tokenizer(words)\n",
    "print(\"custom:\", custom_tokenizer.word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedtest_text = \"\"\"\n",
    "ครบรอบ 14 ปี ตากใบ เช้าวันนั้น 25 ต.ค. 2547 ผู้ชุมนุมชายกว่า 1,370 คน\n",
    "ถูกโยนขึ้นรถยีเอ็มซี 22 หรือ 24 คัน นอนซ้อนกันคันละ 4-5 ชั้น เดินทางจากสถานีตำรวจตากใบ ไปไกล 150 กิโลเมตร\n",
    "ไปถึงค่ายอิงคยุทธบริหาร ใช้เวลากว่า 6 ชั่วโมง / ในอีกคดีที่ญาติฟ้องร้องรัฐ คดีจบลงที่การประนีประนอมยอมความ\n",
    "กระทรวงกลาโหมจ่ายค่าสินไหมทดแทนรวม 42 ล้านบาทให้กับญาติผู้เสียหาย 79 ราย\n",
    "ปิดหีบและนับคะแนนเสร็จแล้ว ที่หน่วยเลือกตั้งที่ 32 เขต 13 แขวงหัวหมาก เขตบางกะปิ กรุงเทพมหานคร\n",
    "ผู้สมัคร ส.ส. และตัวแทนพรรคการเมืองจากหลายพรรคต่างมาเฝ้าสังเกตการนับคะแนนอย่างใกล้ชิด โดย\n",
    "ฐิติภัสร์ โชติเดชาชัยนันต์ จากพรรคพลังประชารัฐ และพริษฐ์ วัชรสินธุ จากพรรคประชาธิปัตย์ได้คะแนน\n",
    "96 คะแนนเท่ากัน\n",
    "เช้าวันอาทิตย์ที่ 21 เมษายน 2019 ซึ่งเป็นวันอีสเตอร์ วันสำคัญของชาวคริสต์\n",
    "เกิดเหตุระเบิดต่อเนื่องในโบสถ์คริสต์และโรงแรมอย่างน้อย 7 แห่งในประเทศศรีลังกา\n",
    "มีผู้เสียชีวิตแล้วอย่างน้อย 156 คน และบาดเจ็บหลายร้อยคน ยังไม่มีข้อมูลว่าผู้ก่อเหตุมาจากฝ่ายใด\n",
    "จีนกำหนดจัดการประชุมข้อริเริ่มสายแถบและเส้นทางในช่วงปลายสัปดาห์นี้ ปักกิ่งยืนยันว่า\n",
    "อภิมหาโครงการเชื่อมโลกของจีนไม่ใช่เครื่องมือแผ่อิทธิพล แต่ยินดีรับฟังข้อวิจารณ์ เช่น ประเด็นกับดักหนี้สิน\n",
    "และความไม่โปร่งใส รัฐบาลปักกิ่งบอกว่า เวทีประชุม Belt and Road Forum ในช่วงวันที่ 25-27 เมษายน\n",
    "ถือเป็นงานการทูตที่สำคัญที่สุดของจีนในปี 2019\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 8.68 ms, total: 1.06 s\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "# Speed test: Calling \"longest\" engine through word_tokenize wrapper\n",
    "%time tokens = word_tokenize(speedtest_text, engine=\"longest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.6 ms, sys: 235 µs, total: 11.8 ms\n",
      "Wall time: 11.8 ms\n"
     ]
    }
   ],
   "source": [
    "# Speed test: Calling \"newmm\" engine through word_tokenize wrapper\n",
    "%time tokens = word_tokenize(speedtest_text, engine=\"newmm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 ms, sys: 562 µs, total: 11.1 ms\n",
      "Wall time: 12.4 ms\n"
     ]
    }
   ],
   "source": [
    "# Speed test: Directly call \"newmm\" engine from pythainlp.tokenize.newmm\n",
    "%time tokens = pythainlp.tokenize.newmm.segment(speedtest_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['มี|ความ|เป็น|ไป|ได้|อย่าง|ไร|บ้าง|',\n",
       " 'มี|ความ|เป็นไป|ได้|อย่าง|ไร|บ้าง|',\n",
       " 'มี|ความ|เป็นไปได้|อย่าง|ไร|บ้าง|',\n",
       " 'มี|ความเป็นไป|ได้|อย่าง|ไร|บ้าง|',\n",
       " 'มี|ความเป็นไปได้|อย่าง|ไร|บ้าง|',\n",
       " 'มี|ความ|เป็น|ไป|ได้|อย่างไร|บ้าง|',\n",
       " 'มี|ความ|เป็นไป|ได้|อย่างไร|บ้าง|',\n",
       " 'มี|ความ|เป็นไปได้|อย่างไร|บ้าง|',\n",
       " 'มี|ความเป็นไป|ได้|อย่างไร|บ้าง|',\n",
       " 'มี|ความเป็นไปได้|อย่างไร|บ้าง|',\n",
       " 'มี|ความ|เป็น|ไป|ได้|อย่างไรบ้าง|',\n",
       " 'มี|ความ|เป็นไป|ได้|อย่างไรบ้าง|',\n",
       " 'มี|ความ|เป็นไปได้|อย่างไรบ้าง|',\n",
       " 'มี|ความเป็นไป|ได้|อย่างไรบ้าง|',\n",
       " 'มี|ความเป็นไปได้|อย่างไรบ้าง|']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all possible segmentations\n",
    "from pythainlp.tokenize.multi_cut import find_all_segment, mmcut, segment\n",
    "\n",
    "find_all_segment(\"มีความเป็นไปได้อย่างไรบ้าง\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subword and Thai Character Cluster (TCC)\n",
    "\n",
    "According to [Character Cluster Based Thai Information Retrieval](https://www.researchgate.net/publication/2853284_Character_Cluster_Based_Thai_Information_Retrieval) (Theeramunkong et al. 2004)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ป', 'ระ', 'เท', 'ศ', 'ไท', 'ย']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pythainlp import subword_tokenize\n",
    "\n",
    "subword_tokenize(\"ประเทศไทย\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low-level TCC operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ป', 'ระ', 'เท', 'ศ', 'ไท', 'ย']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pythainlp.tokenize import tcc\n",
    "\n",
    "tcc.segment(\"ประเทศไทย\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 3, 5, 6, 8, 9}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcc.tcc_pos(\"ประเทศไทย\")  # return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ป-ระ-เท-ศ-ไท-ย-"
     ]
    }
   ],
   "source": [
    "for ch in tcc.tcc(\"ประเทศไทย\"):  # generator\n",
    "    print(ch, end='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transliteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maeo'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pythainlp.transliterate import romanize\n",
    "\n",
    "romanize(\"แมว\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mɛːw'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pythainlp.transliterate import transliterate\n",
    "\n",
    "transliterate(\"แมว\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pythainlp[icu]\n",
    "#transliterate(\"แมว\", engine=\"icu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pythainlp.util import normalize\n",
    "\n",
    "normalize(\"เเปลก\") == \"แปลก\"  # เ เ ป ล ก  vs แปลก"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soundex\n",
    "\n",
    "\"Soundex is a phonetic algorithm for indexing names by sound.\" ([Wikipedia](https://en.wikipedia.org/wiki/Soundex)). PyThaiNLP provides three kinds of Thai soundex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from pythainlp.soundex import lk82, metasound, udom83\n",
    "\n",
    "# check equivalence\n",
    "print(lk82(\"รถ\") == lk82(\"รด\"))\n",
    "print(udom83(\"วรร\") == udom83(\"วัน\"))\n",
    "print(metasound(\"นพ\") == metasound(\"นภ\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "บูรณะ - lk82: บE400 - udom83: บ930000 - metasound: บ550\n",
      "บูรณการ - lk82: บE419 - udom83: บ931900 - metasound: บ551\n",
      "มัก - lk82: ม1000 - udom83: ม100000 - metasound: ม100\n",
      "มัค - lk82: ม1000 - udom83: ม100000 - metasound: ม100\n",
      "มรรค - lk82: ม1000 - udom83: ม310000 - metasound: ม551\n",
      "ลัก - lk82: ร1000 - udom83: ร100000 - metasound: ล100\n",
      "รัก - lk82: ร1000 - udom83: ร100000 - metasound: ร100\n",
      "รักษ์ - lk82: ร1000 - udom83: ร100000 - metasound: ร100\n",
      " - lk82:  - udom83:  - metasound: \n"
     ]
    }
   ],
   "source": [
    "texts = [\"บูรณะ\", \"บูรณการ\", \"มัก\", \"มัค\", \"มรรค\", \"ลัก\", \"รัก\", \"รักษ์\", \"\"]\n",
    "for text in texts:\n",
    "    print(\n",
    "        \"{} - lk82: {} - udom83: {} - metasound: {}\".format(\n",
    "            text, lk82(text), udom83(text), metasound(text)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spellchecking\n",
    "\n",
    "Default spellchecker uses [Peter Norvig's algorithm](http://www.norvig.com/spell-correct.html) together with word frequency from Thai National Corpus (TNC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['เหลียม', 'เหลือม']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pythainlp import spell\n",
    "\n",
    "# list possible spellings\n",
    "spell(\"เหลืยม\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'เหลียม'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pythainlp import correct\n",
    "\n",
    "# choose the most likely spelling\n",
    "correct(\"เหลืยม\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spellchecking - Custom dictionary and word frequency\n",
    "\n",
    "Custom dictionary can be provided when creating spellchecker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['เหลือม']\n",
      "เหลือม\n"
     ]
    }
   ],
   "source": [
    "from pythainlp.corpus import ttc  # Thai Textbook Corpus\n",
    "from pythainlp.spell import NorvigSpellChecker\n",
    "\n",
    "checker = NorvigSpellChecker(custom_dict=ttc.word_freqs())\n",
    "print(checker.spell(\"เหลืยม\"))\n",
    "print(checker.correct(\"เหลืยม\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ดวงๆ', 3),\n",
       " ('กระพือ', 6),\n",
       " ('อุปสมบท', 17),\n",
       " ('หาเช้ากินค่ำ', 14),\n",
       " ('จะเห็นได้ว่า', 152),\n",
       " ('ยวด', 2),\n",
       " ('กล่อม', 182),\n",
       " ('เต้า', 37),\n",
       " ('จัว', 2)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(checker.dictionary())[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply conditions and filter function to dictionary when creating spellchecker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39977"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker = NorvigSpellChecker()  # use default filter (remove any word with number or non-Thai character)\n",
    "len(checker.dictionary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30379"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker = NorvigSpellChecker(min_freq=5, min_len=2, max_len=15)\n",
    "len(checker.dictionary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76706"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker_no_filter = NorvigSpellChecker(dict_filter=None)  # use no filter\n",
    "len(checker_no_filter.dictionary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76700"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_yamok(word):\n",
    "    return False if \"ๆ\" in word else True\n",
    "\n",
    "checker_custom_filter = NorvigSpellChecker(dict_filter=remove_yamok)  # use custom filter\n",
    "len(checker_custom_filter.dictionary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('การ', 'FIXN'), ('เดินทาง', 'VACT')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pythainlp.tag import pos_tag, pos_tag_sents\n",
    "\n",
    "pos_tag([\"การ\",\"เดินทาง\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('ประกาศสำนักนายกฯ', 'NCMN'),\n",
       "  (' ', 'PUNC'),\n",
       "  ('ให้', 'JSBR'),\n",
       "  (' ', 'PUNC'),\n",
       "  (\"'พล.ท.สรรเสริญ แก้วกำเนิด'\", 'NCMN'),\n",
       "  (' ', 'PUNC'),\n",
       "  ('พ้นจากตำแหน่ง', 'NCMN'),\n",
       "  (' ', 'PUNC'),\n",
       "  ('ผู้ทรงคุณวุฒิพิเศษ', 'NCMN'),\n",
       "  ('กองทัพบก', 'NCMN'),\n",
       "  (' ', 'PUNC'),\n",
       "  ('กระทรวงกลาโหม', 'NCMN')],\n",
       " [('และ', 'JCRG'),\n",
       "  ('แต่งตั้ง', 'VACT'),\n",
       "  ('ให้', 'JSBR'),\n",
       "  ('เป็น', 'VSTA'),\n",
       "  (\"'อธิบดีกรมประชาสัมพันธ์'\", 'NCMN')]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = [[\"ประกาศสำนักนายกฯ\", \" \", \"ให้\",\n",
    "    \" \", \"'พล.ท.สรรเสริญ แก้วกำเนิด'\", \" \", \"พ้นจากตำแหน่ง\",\n",
    "    \" \", \"ผู้ทรงคุณวุฒิพิเศษ\", \"กองทัพบก\", \" \", \"กระทรวงกลาโหม\"],\n",
    "    [\"และ\", \"แต่งตั้ง\", \"ให้\", \"เป็น\", \"'อธิบดีกรมประชาสัมพันธ์'\"]]\n",
    "\n",
    "pos_tag_sents(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named-Entity Tagging\n",
    "\n",
    "The tagger use BIO scheme:\n",
    "- B - beginning of entity\n",
    "- I - inside entity\n",
    "- O - outside entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('15', 'NUM', 'B-DATE'),\n",
       " (' ', 'PUNCT', 'I-DATE'),\n",
       " ('ก.ย.', 'NOUN', 'I-DATE'),\n",
       " (' ', 'PUNCT', 'I-DATE'),\n",
       " ('61', 'NUM', 'I-DATE'),\n",
       " (' ', 'PUNCT', 'O'),\n",
       " ('ทดสอบ', 'VERB', 'O'),\n",
       " ('ระบบ', 'NOUN', 'O'),\n",
       " ('เวลา', 'NOUN', 'O'),\n",
       " (' ', 'PUNCT', 'O'),\n",
       " ('14', 'NOUN', 'B-TIME'),\n",
       " (':', 'PUNCT', 'I-TIME'),\n",
       " ('49', 'NUM', 'I-TIME'),\n",
       " (' ', 'PUNCT', 'I-TIME'),\n",
       " ('น.', 'NOUN', 'I-TIME'),\n",
       " (' ', 'PUNCT', 'O'),\n",
       " ('เดินทาง', 'VERB', 'O'),\n",
       " ('จาก', 'ADP', 'O'),\n",
       " ('กทม.', 'NOUN', 'B-LOCATION'),\n",
       " ('ไป', 'AUX', 'O'),\n",
       " ('จังหวัด', 'NOUN', 'B-LOCATION'),\n",
       " ('กำแพงเพชร', 'NOUN', 'I-LOCATION'),\n",
       " (' ', 'PUNCT', 'I-MONEY'),\n",
       " ('ตั๋ว', 'NOUN', 'I-MONEY'),\n",
       " ('ราคา', 'NOUN', 'I-MONEY'),\n",
       " (' ', 'PUNCT', 'I-MONEY'),\n",
       " ('297', 'NUM', 'I-MONEY'),\n",
       " (' ', 'PUNCT', 'I-MONEY'),\n",
       " ('บาท', 'NOUN', 'I-MONEY')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pythainlp.tag.named_entity import ThaiNameTagger\n",
    "\n",
    "ner = ThaiNameTagger()\n",
    "ner.get_ner(\"15 ก.ย. 61 ทดสอบระบบเวลา 14:49 น. เดินทางจากกทม.ไปจังหวัดกำแพงเพชร ตั๋วราคา 297 บาท\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:summarizer.preprocessing.cleaner:'pattern' package not found; tag filters are not available for English\n",
      "INFO:gensim.models.utils_any2vec:loading projection weights from /Users/arthit/pythainlp-data/thai2vec.bin\n",
      "INFO:gensim.models.utils_any2vec:loaded (60001, 400) matrix from /Users/arthit/pythainlp-data/thai2vec.bin\n",
      "/usr/local/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99259853"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pythainlp.word_vector\n",
    "\n",
    "pythainlp.word_vector.similarity(\"คน\", \"มนุษย์\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.keyedvectors:precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'แมว'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pythainlp.word_vector.doesnt_match([\"คน\", \"มนุษย์\", \"บุคคล\", \"เจ้าหน้าที่\", \"แมว\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number Spell Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'หนึ่งล้านสองแสนสามหมื่นสี่พันห้าร้อยหกสิบเจ็ดล้านแปดแสนเก้าหมื่นหนึ่งร้อยยี่สิบสามบาทสี่สิบห้าสตางค์'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pythainlp.util import bahttext\n",
    "\n",
    "bahttext(1234567890123.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'หนึ่งบาทเก้าสิบเอ็ดสตางค์'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bahttext() will round the satang part\n",
    "bahttext(1.909)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
